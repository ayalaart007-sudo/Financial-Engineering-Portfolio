{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70086771-ad90-497d-9b51-22626c9cce63",
   "metadata": {},
   "source": "# Laboratorio de regresión - 5   Ej 1   Arturo Ayala Hernández"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "500c396aae8108ac"
  },
  {
   "cell_type": "markdown",
   "id": "9f666e0e-9e63-49f4-96e1-053c5b1738c3",
   "metadata": {},
   "source": [
    "|                |                        |\n",
    ":----------------|------------------------|\n",
    "| **Nombre**     | Arturo Ayala Hernández |\n",
    "| **Fecha**      | 16/02/26               |\n",
    "| **Expediente** | 758742                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f352dc-5863-4685-af3c-25f8fcf60841",
   "metadata": {},
   "source": [
    "## Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fccec-9651-4f74-9d56-a3c2b2097e19",
   "metadata": {},
   "source": [
    "Hemos estado usando `train_test_split` en nuestros modelos anteriores.\n",
    "\n",
    "¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe97ab-a033-4d0f-ab73-0cdabe591655",
   "metadata": {},
   "source": [
    "Porque necesitamos probar el modelo con datos que NO haya visto antes.\n",
    "\n",
    "Si el modelo estudia con las respuestas a la mano, sacará 100 en el examen pero no habrá aprendido nada (eso se llama overfitting). Al separar los datos, simulamos un examen real para ver si de verdad aprendió a predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60a028-ed60-4a5c-9308-dee4862e2bac",
   "metadata": {},
   "source": [
    "Si la muestra es un subset de la población y queremos generalizar sobre la población, ¿no sería mejor utilizar todos los datos al entrenar un modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50989a32-59e7-4bef-9b60-89f543d8ca81",
   "metadata": {},
   "source": [
    "Para aprender sí, pero para evaluar NO.\n",
    "\n",
    "Usar todos los datos es arriesgado porque te quedas sin forma de comprobar si tu modelo funciona.\n",
    "\n",
    "La solución ideal: Usamos validación cruzada (como en este ejercicio) para usar casi todos los datos y aun así poder evaluarlo. Ya que estamos seguros de que funciona, al final sí podemos entrenarlo con todo para usarlo en la vida real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d96f3-7370-4161-aa67-75f10e5817cd",
   "metadata": {},
   "source": [
    "El propósito de volver a muestrear dentro de nuestro dataset es tener una idea de qué tan buena podría ser la generalización de nuestro modelo. Imagina un dataset ya separado en dos mitades. Utilizas la primera mitad para entrenar el modelo y pruebas en la segunda mitad; la segunda mitad eran datos invisibles para el modelo al momento de entrenar. Esto nos lleva a tres escenario típicos:\n",
    "\n",
    "1. Si el modelo hace buenas predicciones en la segunda mitad, significa que la primera mitad era \"suficiente\" para generalizar.\n",
    "2. Si el modelo no hace buenas predicciones en la segunda mitad, pero sí en la primera mitad, podría ser que había información importante en la segunda mitad que debió haber sido tomada en cuenta al entrenar, o un problema de overfitting.\n",
    "3. Si el modelo no hace buenas predicciones en la segunda mitad, y tampoco en la primera mitad, se tendrían que revisar los factores y/o el modelo seleccionado.\n",
    "\n",
    "El caso ideal sería el 1, pero por estadística los errores y varianzas tienen como entrada el número de muestas, por lo que tenemos menos seguridad de nuestros resutados al usar menos muestras. Si vemos que el modelo generaliza bien podemos unir de nuevo el dataset y entrenar sobre el dataset completo.\n",
    "\n",
    "En el caso 2 está el problema de que no podemos saber qué información es necesaria para el entrenamiento apropiado del modelo; esto nos lleva a pensar que debemos usar el dataset completo para entrenar, pero esto nos lleva al mismo problema de no saber si el modelo puede generalizar.\n",
    "\n",
    "El problema sólo incrementa si se tienen hiperparámetros en el modelo (e.g. $\\lambda$ en regularización)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16176ad-41fc-4f3c-b865-2eb4219152e2",
   "metadata": {},
   "source": [
    "## Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7165d-5b5d-4e92-ae7f-7edb12eea745",
   "metadata": {},
   "source": [
    "Este método de validación es una colección de $n$ `train-test-split`. Teniendo un dataset de $n$ muestras, la lógica es:\n",
    "1. Saca una muestra del dataset.\n",
    "2. Entrena tu modelo con las $n-1$ muestras.\n",
    "3. Evalúa tu modelo en la muestra que quedó fuera con el métrico que más se ajuste a la aplicación.\n",
    "4. Regresa la muestra al dataset.\n",
    "5. Repite 1-4 con muestras diferentes hasta haber hecho el procedimiento $n$ veces para $n$ muestras.\n",
    "6. Calcula la media y desviación estándar de los métricos guardados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21340b80-8fa4-4cdf-8fe4-85e4a35febcd",
   "metadata": {},
   "source": [
    "Con los resultados del proceso de validación podemos saber qué tan bueno podría ser el modelo seleccionado con los datos (con/sin transformaciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0983bf1c-a6a2-42e4-a522-92bba6b450ab",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5f076-bc52-482c-9560-ecd0c125efa7",
   "metadata": {},
   "source": [
    "Utiliza el dataset `Motor Trend Car Road Tests`. Elimina la columna `model` y entrena 32 modelos diferentes utilizando Leave-One-Out Cross Validation con target `mpg`. Utiliza MSE como métrico."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Carga de librerías y preprocesamiento\n",
    "Cargamos el dataset `Motor Trend Car Road Tests.xlsx` y eliminamos la columna `model` (texto) para quedarnos solo con las variables numéricas."
   ],
   "id": "32fdd6ff2380210"
  },
  {
   "cell_type": "code",
   "id": "89510da9-15a9-41e5-bd0e-855291acec2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T23:39:08.967539100Z",
     "start_time": "2026-02-16T23:39:07.835580200Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Carga de datos\n",
    "df = pd.read_excel('Motor Trend Car Road Tests.xlsx')\n",
    "\n",
    "# Eliminar la columna 'model'\n",
    "df_clean = df.drop(columns=['model'])\n",
    "\n",
    "# Mostrar las primeras filas para verificar\n",
    "print(df_clean.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
      "0  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n",
      "1  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
      "2  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n",
      "3  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
      "4  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Definición de variables\n",
    "Separamos la variable objetivo $y$ (`mpg`) de las variables predictoras $X$ (todo lo demás). Convertimos los datos a arreglos de `numpy` para facilitar la manipulación manual de los índices."
   ],
   "id": "dad921220e309951"
  },
  {
   "cell_type": "code",
   "id": "b7199ca1-32f0-463b-925f-76613d608a72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T23:39:08.990569200Z",
     "start_time": "2026-02-16T23:39:08.975440200Z"
    }
   },
   "source": [
    "# Variables predictoras (X) y Target (y)\n",
    "X = np.array(df_clean.drop(columns=['mpg']))\n",
    "y = np.array(df_clean['mpg'])\n",
    "\n",
    "# número total de muestras (n)\n",
    "n = len(X)\n",
    "print(f\"Total de muestras (autos): {n}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de muestras (autos): 32\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.  Leave-One-Out CV\n",
    "Realizamos un ciclo que se repite $n$ veces (32 iteraciones). En cada vuelta:\n",
    "1.  **Separamos** un auto para prueba (Test) y usamos los 31 restantes para entrenar (Train).\n",
    "2.  **Entrenamos** el modelo de Regresión Lineal.\n",
    "3.  **Predecimos** el valor del auto oculto.\n",
    "4.  **Calculamos** el Error Cuadrático (MSE) y lo guardamos."
   ],
   "id": "7cad59ccdd17f675"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T23:39:09.026005400Z",
     "start_time": "2026-02-16T23:39:08.990569200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lista para guardar los errores\n",
    "errores_individuales = []\n",
    "\n",
    "print(\"Iniciando validación cruzada...\")\n",
    "\n",
    "for i in range(n):\n",
    "    # --- Paso A: Separar Train y Test ---\n",
    "    # Test: El auto 'i' (usamos reshape porque es un solo dato)\n",
    "    X_test = X[i].reshape(1, -1)\n",
    "    y_test = y[i].reshape(1, -1)\n",
    "\n",
    "    # Train: Todos los autos MENOS el 'i' (axis=0 borra la fila)\n",
    "    X_train = np.delete(X, i, axis=0)\n",
    "    y_train = np.delete(y, i, axis=0)\n",
    "\n",
    "    # --- Paso B: Entrenar Modelo ---\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # --- Paso C: Predecir ---\n",
    "    prediccion = lr.predict(X_test)\n",
    "\n",
    "    # --- Paso D: Calcular Error ---\n",
    "    error = mean_squared_error(y_test, prediccion)\n",
    "    errores_individuales.append(error)\n",
    "\n",
    "print(\"Validación completada.\")"
   ],
   "id": "edaf0c47f07c94fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando validación cruzada...\n",
      "Validación completada.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "b19904df-1fe6-433a-b1bd-a7ce86ce0eef",
   "metadata": {},
   "source": [
    "### 4. Resultados Generales\n",
    "Calculamos el promedio de los errores obtenidos en cada iteración para obtener el **MSE Global** del modelo."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T23:39:09.055303300Z",
     "start_time": "2026-02-16T23:39:09.026005400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Promedio de todos los errores\n",
    "mse_promedio = np.mean(errores_individuales)\n",
    "\n",
    "print(f\"MSE Promedio (Mean Squared Error): {mse_promedio}\")\n",
    "print(f\"Raíz del MSE (RMSE): {np.sqrt(mse_promedio)}\")"
   ],
   "id": "e68d178f75499285",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Promedio (Mean Squared Error): 12.181558006901948\n",
      "Raíz del MSE (RMSE): 3.490208877259633\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Interpretación\n",
    "\n",
    "Interpretación:\n",
    "\n",
    "El resultado nos dio un RMSE de 3.49.\n",
    "\n",
    "Esto significa que, cada vez que intentamos predecir el rendimiento de un auto nuevo, el modelo se equivoca (en promedio) por unas 3.5 millas por galón. Es el margen de error normal de este modelo."
   ],
   "id": "5f5329a4d3f474ba"
  },
  {
   "cell_type": "markdown",
   "id": "dbc61dd1-fa5f-43b0-969a-592f8e9fc56f",
   "metadata": {},
   "source": [
    "## K-Folds Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbca526-2c69-4c70-b6b4-270fc51d825b",
   "metadata": {},
   "source": [
    "El dataset `Motor Trend Car Road Tests` sólo tiene 32 muestras, y utilizar un modelo sencillo de regresión múltiple hace que usar LOOCV sea muy rápido. El dataset `California Housing` tiene $20640$ muestras para $9$ columnas, entonces realizar un ajuste sobre una transformación o sobre el modelo y luego calcular el impacto esperado podría tomar más tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a437812-c00e-400f-ae7d-110b3afa5dc3",
   "metadata": {},
   "source": [
    "La solución propuesta es dividir el dataset en *k* folds (partes iguales), ajustar en *k-1* folds y probar en el restante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb82cc3-0d35-442a-a12b-f9c6fd131af2",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "Utiliza el dataset `California Housing` y haz K-folds Cross Validation con 10 folds. Utiliza el MSE como métrico."
   ]
  },
  {
   "cell_type": "code",
   "id": "ba50e361-edcd-4cdb-9609-68f20d6fca97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T23:39:09.130671300Z",
     "start_time": "2026-02-16T23:39:09.055303300Z"
    }
   },
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(\"Dataset Shape:\", housing.data.shape, housing.target.shape)\n",
    "print(\"Dataset Features:\", housing.feature_names)\n",
    "print(\"Dataset Target:\", housing.target_names)\n",
    "X = housing.data\n",
    "y = housing.target"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (20640, 8) (20640,)\n",
      "Dataset Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "Dataset Target: ['MedHouseVal']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "4e8570a4-76bb-4d81-a90b-43647b0df438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T23:39:09.139925200Z",
     "start_time": "2026-02-16T23:39:09.133108700Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "54f44358-f47d-493b-93cf-10aa2314fa20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T23:39:09.144359900Z",
     "start_time": "2026-02-16T23:39:09.139925200Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "34f7098f-a1de-4508-b3ff-af1484561856",
   "metadata": {},
   "source": [
    "Interpreta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbaf4d-f62b-46d9-9a35-23fcdd50a8ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "333c8039-5b38-4835-a523-d4f6f7a7040b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da5792ac-6d38-4f02-bf10-aeaa0a040d17",
   "metadata": {},
   "source": [
    "## Referencia\n",
    "\n",
    "James, G., Witten, D., Hastie, T., Tibshirani, R.,, Taylor, J. (2023). An Introduction to Statistical Learning with Applications in Python. Cham: Springer. ISBN: 978-3-031-38746-3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
