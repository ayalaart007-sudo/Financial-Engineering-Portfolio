{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# Análisis de Regresión: Motor Trend Car Road Tests Arturo Ayala Hernández\n",
    "Importamos las librerías necesarias y cargamos el dataset, eliminando la columna `model` ya que es un identificador de texto y no aporta valor predictivo numérico a la regresión."
   ],
   "id": "14792873c55a87b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T02:46:14.529194600Z",
     "start_time": "2026-02-20T02:46:12.802105800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# Cargar el archivo de datos (asegúrate de que el nombre coincida con tu archivo local)\n",
    "df = pd.read_excel('Motor Trend Car Road Tests.xlsx')\n",
    "\n",
    "# Eliminamos la columna 'model'\n",
    "df_base = df.drop(columns=['model'])"
   ],
   "id": "982430551f56c7e2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Actividad 1.1: Regresión con 'mpg' como salida (Variables continuas/ordinales)\n",
    "Calcularemos el R2 del modelo completo, interpretaremos los coeficientes (betas), realizaremos un Train-Test Split (40% para entrenar) y probaremos regularización L2 (Ridge) ajustando el hiperparámetro lambda."
   ],
   "id": "72539af7d13d305f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T02:46:14.564766600Z",
     "start_time": "2026-02-20T02:46:14.533446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definir X e y\n",
    "X_11 = df_base.drop(columns=['mpg'])\n",
    "y_11 = df_base['mpg']\n",
    "\n",
    "# 1. Modelo Completo\n",
    "modelo_11 = LinearRegression()\n",
    "modelo_11.fit(X_11, y_11)\n",
    "print(f\"R2 Modelo Completo: {modelo_11.score(X_11, y_11):.4f}\")\n",
    "\n",
    "print(\"\\nBetas (Coeficientes):\")\n",
    "for feature, coef in zip(X_11.columns, modelo_11.coef_):\n",
    "    print(f\" - {feature}: {coef:.4f}\")\n",
    "\n",
    "# 2. Train-Test Split (40% train)\n",
    "X_train_11, X_test_11, y_train_11, y_test_11 = train_test_split(X_11, y_11, train_size=0.4, random_state=42)\n",
    "modelo_11_split = LinearRegression()\n",
    "modelo_11_split.fit(X_train_11, y_train_11)\n",
    "print(f\"\\nR2 Entrenamiento: {modelo_11_split.score(X_train_11, y_train_11):.4f}\")\n",
    "print(f\"R2 Prueba: {modelo_11_split.score(X_test_11, y_test_11):.4f}\")\n",
    "\n",
    "# 3. Regularización L2 (Ridge)\n",
    "print(\"\\nRegularización Ridge con distintos Lambdas (Alphas):\")\n",
    "for alpha_val in [0.1, 1.0, 10.0, 100.0]:\n",
    "    ridge_11 = Ridge(alpha=alpha_val)\n",
    "    ridge_11.fit(X_train_11, y_train_11)\n",
    "    r2_train = ridge_11.score(X_train_11, y_train_11)\n",
    "    r2_test = ridge_11.score(X_test_11, y_test_11)\n",
    "    print(f\" Lambda = {alpha_val:5.1f} | Train R2: {r2_train:.4f} | Test R2: {r2_test:.4f}\")"
   ],
   "id": "6ead45673ca1406e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Modelo Completo: 0.8690\n",
      "\n",
      "Betas (Coeficientes):\n",
      " - cyl: -0.1114\n",
      " - disp: 0.0133\n",
      " - hp: -0.0215\n",
      " - drat: 0.7871\n",
      " - wt: -3.7153\n",
      " - qsec: 0.8210\n",
      " - vs: 0.3178\n",
      " - am: 2.5202\n",
      " - gear: 0.6554\n",
      " - carb: -0.1994\n",
      "\n",
      "R2 Entrenamiento: 0.9982\n",
      "R2 Prueba: -7.1071\n",
      "\n",
      "Regularización Ridge con distintos Lambdas (Alphas):\n",
      " Lambda =   0.1 | Train R2: 0.9794 | Test R2: 0.2607\n",
      " Lambda =   1.0 | Train R2: 0.9279 | Test R2: 0.6311\n",
      " Lambda =  10.0 | Train R2: 0.8634 | Test R2: 0.6567\n",
      " Lambda = 100.0 | Train R2: 0.8073 | Test R2: 0.5990\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Interpretación 1.1:**\n",
    "* **Betas Positivas (`drat`, `qsec`, `am`, `gear`):** Un aumento en estas características (ej. autos manuales o con más engranajes) favorece el rendimiento de combustible (mpg).\n",
    "* **Betas Negativas (`wt`, `hp`, `cyl`):** Un auto más pesado, potente o con más cilindros reduce significativamente el `mpg`.\n",
    "* **Desempeño y L2:** Al usar solo el 40% de los datos, el modelo sin regularizar se sobreajusta (R2 Test negativo). Al aplicar Ridge con un Lambda alrededor de 10.0, penalizamos los coeficientes, sacrificando exactitud en entrenamiento pero rescatando la capacidad predictiva en datos de prueba."
   ],
   "id": "9b81afafd4a99798"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Actividad 1.2: Regresión con 'qsec' como salida\n",
    "Repetimos el proceso anterior, pero ahora intentamos predecir el tiempo en el cuarto de milla (`qsec`)."
   ],
   "id": "88ee7edd5f608c67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T02:46:14.590736300Z",
     "start_time": "2026-02-20T02:46:14.567549400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_12 = df_base.drop(columns=['qsec'])\n",
    "y_12 = df_base['qsec']\n",
    "\n",
    "modelo_12 = LinearRegression()\n",
    "modelo_12.fit(X_12, y_12)\n",
    "print(f\"R2 Modelo Completo: {modelo_12.score(X_12, y_12):.4f}\")\n",
    "\n",
    "print(\"\\nBetas (Coeficientes):\")\n",
    "for feature, coef in zip(X_12.columns, modelo_12.coef_):\n",
    "    print(f\" - {feature}: {coef:.4f}\")\n",
    "\n",
    "X_train_12, X_test_12, y_train_12, y_test_12 = train_test_split(X_12, y_12, train_size=0.4, random_state=42)\n",
    "modelo_12_split = LinearRegression()\n",
    "modelo_12_split.fit(X_train_12, y_train_12)\n",
    "print(f\"\\nR2 Entrenamiento: {modelo_12_split.score(X_train_12, y_train_12):.4f}\")\n",
    "print(f\"R2 Prueba: {modelo_12_split.score(X_test_12, y_test_12):.4f}\")"
   ],
   "id": "b48dbfbe261b1a3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Modelo Completo: 0.8747\n",
      "\n",
      "Betas (Coeficientes):\n",
      " - mpg: 0.0690\n",
      " - cyl: -0.3627\n",
      " - disp: -0.0075\n",
      " - hp: -0.0016\n",
      " - drat: -0.1311\n",
      " - wt: 1.4963\n",
      " - vs: 0.9700\n",
      " - am: -0.9012\n",
      " - gear: -0.2013\n",
      " - carb: -0.2736\n",
      "\n",
      "R2 Entrenamiento: 0.9989\n",
      "R2 Prueba: -1.0013\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Interpretación 1.2:**\n",
    "* **Betas:** El peso (`wt`) tiene un signo fuertemente positivo (hace el auto más lento), mientras que `hp` (caballos de fuerza) y transmisiones manuales (`am`) tienen signos negativos, reduciendo el tiempo del auto (haciéndolo más rápido).\n",
    "* **Train/Test:** Nuevamente existe un sobreajuste evidente debido al alto número de variables frente a muy pocos datos de entrenamiento."
   ],
   "id": "2a25b52090c790e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Actividad 2.1: Regresión con 'mpg' (Usando Variables Dummies)\n",
    "Transformamos las columnas categóricas (`cyl`, `gear`, `carb`) en variables dummies y calculamos las métricas."
   ],
   "id": "5f16465d968f0c5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T02:46:14.634342Z",
     "start_time": "2026-02-20T02:46:14.593299900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Crear dummies dropeando la primera categoría para evitar la trampa de colinealidad\n",
    "df_dummies = pd.get_dummies(df_base, columns=['cyl', 'gear', 'carb'], drop_first=True)\n",
    "\n",
    "X_21 = df_dummies.drop(columns=['mpg'])\n",
    "y_21 = df_dummies['mpg']\n",
    "\n",
    "# 1. Modelo Completo\n",
    "modelo_21 = LinearRegression()\n",
    "modelo_21.fit(X_21, y_21)\n",
    "print(f\"R2 Modelo Completo: {modelo_21.score(X_21, y_21):.4f}\")\n",
    "\n",
    "print(\"\\nBetas (Coeficientes con Dummies):\")\n",
    "for feature, coef in zip(X_21.columns, modelo_21.coef_):\n",
    "    print(f\" - {feature}: {coef:.4f}\")\n",
    "\n",
    "# 2. Train-Test Split (40% train)\n",
    "X_train_21, X_test_21, y_train_21, y_test_21 = train_test_split(X_21, y_21, train_size=0.4, random_state=42)\n",
    "modelo_21_split = LinearRegression()\n",
    "modelo_21_split.fit(X_train_21, y_train_21)\n",
    "print(f\"\\nR2 Entrenamiento: {modelo_21_split.score(X_train_21, y_train_21):.4f}\")\n",
    "print(f\"R2 Prueba: {modelo_21_split.score(X_test_21, y_test_21):.4f}\")"
   ],
   "id": "23db5cfdfa1be694",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Modelo Completo: 0.8931\n",
      "\n",
      "Betas (Coeficientes con Dummies):\n",
      " - disp: 0.0355\n",
      " - hp: -0.0705\n",
      " - drat: 1.1828\n",
      " - wt: -4.5298\n",
      " - qsec: 0.3678\n",
      " - vs: 1.9309\n",
      " - am: 1.2121\n",
      " - cyl_6: -2.6487\n",
      " - cyl_8: -0.3362\n",
      " - gear_4: 1.1144\n",
      " - gear_5: 2.5284\n",
      " - carb_2: -0.9794\n",
      " - carb_3: 2.9996\n",
      " - carb_4: 1.0914\n",
      " - carb_6: 4.4776\n",
      " - carb_8: 7.2504\n",
      "\n",
      "R2 Entrenamiento: 1.0000\n",
      "R2 Prueba: -1.3253\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Interpretación 2.1:**\n",
    "* Al usar variables dummies, la primera categoría funciona como nuestro punto de referencia o \"base\" (ej. autos de 4 cilindros, 3 engranajes).\n",
    "* **Betas de Cilindros (`cyl_6`: -2.64, `cyl_8`: -0.33):** Tener 6 u 8 cilindros disminuye el rendimiento (mpg) en comparación con tener 4 cilindros. Curiosamente, en este modelo lineal multivariable, pasar a 6 cilindros tiene un impacto negativo más fuerte que pasar a 8, ya que otras variables (como el peso o el motor) están absorbiendo la varianza.\n",
    "* **Betas de Engranajes (`gear_4`: +1.11, `gear_5`: +2.52):** Un auto con 4 o 5 engranajes aumenta notablemente el `mpg` respecto a un auto de solo 3 engranajes.\n",
    "* **Train/Test:** El sobreajuste en el split de entrenamiento (1.0000) es absoluto, ya que al crear dummies aumentamos la cantidad de columnas (dimensiones), permitiendo al modelo memorizar los limitados datos del 40% de la muestra."
   ],
   "id": "aefec917412d806d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Actividad 2.2: Regresión con 'qsec' (Usando Variables Dummies)\n",
    "Igual que el paso anterior, pero predecimos `qsec`."
   ],
   "id": "e375f564b581f570"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T02:46:14.673163Z",
     "start_time": "2026-02-20T02:46:14.648188900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_22 = df_dummies.drop(columns=['qsec'])\n",
    "y_22 = df_dummies['qsec']\n",
    "\n",
    "modelo_22 = LinearRegression()\n",
    "modelo_22.fit(X_22, y_22)\n",
    "print(f\"R2 Modelo Completo: {modelo_22.score(X_22, y_22):.4f}\")\n",
    "\n",
    "X_train_22, X_test_22, y_train_22, y_test_22 = train_test_split(X_22, y_22, train_size=0.4, random_state=42)\n",
    "modelo_22_split = LinearRegression()\n",
    "modelo_22_split.fit(X_train_22, y_train_22)\n",
    "print(f\"R2 Entrenamiento: {modelo_22_split.score(X_train_22, y_train_22):.4f}\")\n",
    "print(f\"R2 Prueba: {modelo_22_split.score(X_test_22, y_test_22):.4f}\")"
   ],
   "id": "e311b93c2109cdda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Modelo Completo: 0.9083\n",
      "R2 Entrenamiento: 1.0000\n",
      "R2 Prueba: -0.0600\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Actividad 3: Comparación de R2\n",
    "\n",
    "**3.1 Comparación para 'mpg' (1.1 vs 2.1):**\n",
    "* **Modelo 1.1 (Sin Dummies):** R2 Completo: 0.8690 | R2 Train: 0.9982 | R2 Test: -7.1071\n",
    "* **Modelo 2.1 (Con Dummies):** R2 Completo: 0.8931 | R2 Train: 1.0000 | R2 Test: -1.3253\n",
    "* **Conclusión:** Añadir variables dummies mejora la capacidad del modelo para explicar el total de los datos (R2 Completo sube a 89.3%), ya que permite que los cambios de categoría (ej. pasar de 4 a 6 cilindros) tengan impactos independientes. Al evaluar el split, observamos que las dummies llevaron al modelo a una \"memorización\" perfecta (R2 Train de 1.0) por el exceso de columnas frente a tan pocos datos, pero curiosamente el error en datos nuevos (Test) fue menos destructivo (-1.32 vs -7.10).\n",
    "\n",
    "**3.2 Comparación para 'qsec' (1.2 vs 2.2):**\n",
    "* **Modelo 1.2 (Sin Dummies):** R2 Completo: 0.8747 | R2 Train: 0.9989 | R2 Test: -1.0013\n",
    "* **Modelo 2.2 (Con Dummies):** R2 Completo: 0.9083 | R2 Train: 1.0000 | R2 Test: -0.0600\n",
    "* **Conclusión:** El comportamiento es idéntico. Tratar características ordinales mediante dummies elevó la precisión descriptiva sobre el total de datos (superando el 90% de la varianza explicada). Al evaluar el modelo en el set de prueba, las dummies amortiguaron enormemente el margen de error del sobreajuste (-0.06 frente a -1.00), dejándolo muy cerca de hacer predicciones neutrales frente a predecir puro ruido. El sobreajuste es un subproducto inevitable de tener un `train_size` del 40% (solo unos ~12 autos) para ajustar tantas variables."
   ],
   "id": "b1abaf5ad090b113"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
